Response to the referee

We are grateful to the referee for their helpful and constructive comments. We believe that some of the issues raised by the referee may be result of a misunderstanding, and have realized that perhaps our text was not as clear as it should have been. We have expanded explanations in several cases, and have added a new section with caveats, as well as a data analysis on real NuSTAR data for illustrative purposes (all changes are marked in bold). Below, we lay out in detail our changes to the manuscript, and respond directly to the points the referee has raised. We hope that this helps solve the misunderstanding and satisfactorily addresses the referee's concern.
 
> Re. (i) Even for large Signal-to-noise (S/N) the co-spectrum is entirely insensitive to some oscillations with wrong phase. To my knowledge, no else known method suffers
> from such a weakness. Though remedies exist, the distributions discussed in the paper do not apply to them.
and

> 2. Re. (ii) and (iii) Fig. 3 reveals that the simulations were set up so, that the inserted oscillation remains in phase with the reference signal component, resulting with a large positive peak at the corresponding frequency. In the real word, the phases would be randomly distributed and both positive, negative and near null values would be observed.

The primary use case for the distributions defined in the manuscript are cases where observations were taken simultaneously of the same source with independent, identical detectors. This is now standard practice for multiple X-ray missions (including the now defunct RXTE, currently operating NuSTAR and AstroSAT, and future missions like IXPE). The practice of using the cospectrum of time series observed from two independent detectors, rather than the periodogram of the combined time series, was pioneered in NuSTAR as a means to mitigate the effects of dead time (and has since been used is >20 papers). However, the *underlying data stream* from the source is exactly the same. By definition, any periodic signal, be it in an X-ray pulsar or an accreting X-ray binary, must be strictly phase-aligned if it was observed simultaneously with detectors on the same spacecraft. We acknowledge that this might not be true for observations e.g. where the two time series were observed in different energy bands, since periods might be phase-shifted. We have clarified this point in the text at several occasions (in the Introduction, Section 2 as well as the new section "Caveats") and pointed out failure points.
 
Even if observations were taken e.g. in different energy bands, the cases we consider here always consider simultaneous observations of the same object, usually compact objects including pulsars, accreting neutron stars, or accreting black holes. While phase shifts are observed for different energy ranges, it is rather unlikely that the phases in the two observed time series are not covariant with each other, that is, while the *phase* itself might vary randomly if the underlying physical process is random, the phase *shift* will be set by specific (deterministic) conditions in the source (e.g. the geometry) and will therefore not be random. Phase shifts by exactly 90 or 270 degrees are rare in practice, thus while detectability may be diminished, it is still worthwhile to search for it. We have clarified this further in the new Section 3 "Caveats". 

> Re. (ii) The paper deals with a straw man set entirely in virtual reality.
> The quoted references indicate that the authors have access to real observations,
> yet make no attempt to analyze them with the proposed method.  

As described above, the common practice of using the cospectrum derived from two identical detectors implies that we disagree with the referee on the point that the case discussed in the paper does not exist in reality. In particular, the primary reason this manuscript came into being is that we were both approached independently and asked how to define the statistical distributions for the cospectrum in the case of X-ray pulsation searches with NuSTAR. This, combined with the erroneous assumptions made about the statistical distributions used in the current astronomy literature on the topic (primarily the use of the Chi-square and normal distributions), led us to believe that a manuscript laying out the correct statistical distributions to be used is warranted.

In response to the referee's comments, we have analyzed a set of NuSTAR observations of the bright X-ray pulsar Hercules X-1, and present the results in Section 4.2. In particular, we find that the pulsar observations are heavily affected by dead time, rendering the standard periodogram largely unusable. We also find that the cospectral densities follow the distributions laid out in the paper very closely, indicating that the distributions laid out are useful in practice.

> Re. (iii) The authors make implicit assumptions which neither are obvious nor properly explained in the text. Thus the critical dependence of Co-spectrum on oscillation phase
> in not mentioned nor the fact that the only even-sampled observations are considered.
> This, and points (i) and (ii) are likely to confuse rather then enlighten a reader fresh in the field.

We have made our assumptions more explicit throughout the text, particularly in Section 2.

> 3. Re. (iii) Editing of Sect. 2.1 till Eq. (4) is so bad that it becomes source of major confusion for the reader. The text mentions a range of observation times without indication that it is implicitly assumed that observations are even-spaced. To demonstrate so suffice a counterexample of N(-) and N(+) of noise observations clustered around +/-T/2. Except for high frequencies, Fourier transform becomes [a exp(-i omega T/2) + b exp(+i omega T/2)] where Var(a)~1/N(-) differs from Var(b)~1/N(+), contrary to statements past Eq. (6).

We have edited Section 2.1 for clarity, and have explicitly stated that observations must be evenly sampled (and suggest alternative approaches if they are not).

> 4. A subtle flaw, common yet possibly serious of the derivations in the paper stems from assumption of known mean value 0 of x. This holds for simulations yet would be inappropriate for any real observations. Likely the central parts of the distributions would remain largely unaffected, yet their tails, important for the detection criteria, my be seriously affected possibly invalidating the said criteria. While precise accounting for this effect may be difficult, at least some limits to this spoiling effect should be provided.
 
We believe that there is a misunderstanding here. It is not the time series x that has a mean of zero, which indeed is unphysical, especially for photon counting data (and all simulations used in the paper use photon counting statistics and a mean count rate >0). Instead, the *Fourier amplitudes* have a mean of zero at a given frequency. This assumption will be true for any time series that is a realization of a wide-sense stationary stochastic process. For the simplest case of white noise, the Fourier amplitudes will be defined as A_j = \sum(x_k cos(omega_j*t_k)) and B_j = = \sum(x_k sin(omega_j*t_k)) where the sum is over k time intervals and omega_j is an angular frequency. If the x_k data points are distributed according to a normal distribution with mean \mu and variance \sigma^2 (where the mean could vary as a function of time, \mu = \mu_k), the distribution of the data points x_k with the sine or cosine will lead to a new normally distributed variable with a new mean of \mu_k*cos(omega_j*t_k) and a new variance of \mu_k*cos^2(omega_j*t_k). For frequencies between \nu_0 = 1/T up to the Nyquist frequency, this leads to values that are equally distributed around positive and negative means, and the distribution of the sum of all k values will not be exactly zero, but centred around zero. This will be true even when the process is not white noise, but a stationary "red noise" process, because the direction in either positive or negative direction of the time series around a mean is random, and thus the resulting Fourier amplitudes can tend to be either positive or negative.

This assumption underlies all of X-ray timing, and it is worth noting that in neither of us authors has encountered a case where this assumption has not been true, unless the time series was not a random process, not stationary, not evenly sampled or extremely sparse (with <100 photons in total or so). Thus, we conclude that for the vast majority of applications, this assumption will hold. We did add a statement in the relevant Section 2.1 after Equation 6 to make this more explicit.

> 5. while discussing signal from different detectors the authors do not mention an obvious option of adding power spectra to smooth out noise interference.

Averaging periodograms is a standard method to improve the signal-to-noise ratio in period searches. However, in this specific case of dead time, it is ineffective. Dead time occurs when after recording of a photon, it cannot detect another photon within a certain time span (it is, effectively, dead). This leads to a loss of overall photons, but also to a deviation from the typical Poisson process for photon arrival times to a process that involves a characteristic time scale. The resulting periodogram will show an oscillatory pattern over a large range of frequencies (depending on the characteristic time scale of the dead time), and changes both the mean and the variance of the distribution of powers as a function of frequency. Because the effect is always the same at a given frequency, averaging periodograms does not reduce the effect, but rather leads to narrow distributions with an unknown variance around an unknown mean. As an example, we included the periodogram of the NuSTAR observation of Her X-1, for which we averaged the periodograms for 3260 individual light curve segments. The resulting noise distributions are narrow, but deviate very strongly from the expected Chi-square distribution with a mean of 2 and a variance of 2/sqrt(M), where M=3260. This is the primary motivation for the cospectrum as an alternative measure unaffected by dead time.

We have added a short description of the effects of dead time in the Introduction for clarification.

> 6. From the discussion in Sect 2.2.1 the reader could not guess that the
> Central Limit Theorem works here and the purpose of the section is mere check when it becomes good enough approximation.

We have added a half-sentence making that explicit.

> 7. While undoubtedly power spectrum is |F(nu)|^2, there exists a broad class of other estimates of PDF as functions of period/frequency. Hence e.g. wikipedia says: 'In signal processing, a periodogramm is an estimate of the spectral density of a signal ...Today, the periodogramm is a component of more sophisticated methods (see spectral estimation)'. Clearly a generic term is needed and periodogramm would fit nicely here.

Throughout the manuscript, we aim to separate the different Fourier products as clearly as possible. As explained in Footnote 4 on page 1, we exclusively use the term "power spectrum" for the (stochastic) process generating a time series. Conversely, we exclusively use "periodogram" to denote the square of the absolute value of the Fourier amplitudes derived from a realization of the power spectrum, and say "cospectrum" or "cospectral densities" when we refer to the cospectral equivalent of the periodogram. In line with the signal processing literature, the cospectrum is explicitly not a subset of the periodogram, and we have kept those two concepts separate for clarity, since for understanding the paper it is crucial to make clear when we mean the squared Fourier amplitudes of a single time series, and when we mean the product of the Fourier amplitudes of one time series with the complex conjugate of the Fourier amplitude of a second time series. 

